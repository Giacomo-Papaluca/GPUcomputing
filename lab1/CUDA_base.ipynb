{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CUDA_base.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"mount_file_id":"1wUforzwQoKEwtF8BSMcA_xRq4TgeIbfS","authorship_tag":"ABX9TyM/EeU5jQrulOHZV946A41s"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"9YGa6hXkx77o"},"source":["# Google Colaboratory (colab)"]},{"cell_type":"markdown","metadata":{"id":"F-lZoo4TstJn"},"source":["---\n","\n","[Colaboratory](https://research.google.com/colaboratory/faq.html) (or Colab) is a free research tool from Google for machine learning education and research built on top of [Jupyter Notebook](https://jupyter.org/). It is also an ideal tool for scientific collaboration and sharing your results with non-experts (as opposed to, say, collaboration via a GitHub project), especially when there are drastic fluctuations in coding skills across a team/collaboration. This particular notebook starts with a brief overview of Colab's UI and then shows some simple operations in Colab notebooks, including usage of shell commands, file exchange with Google Drive and cuda basic programming. \n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zfPMRBrqzjjb"},"source":["##Upload/download files\n","\n","\n","Once you open a Google Colab notebook, it creates a virtual machine instance on a Google Cloud Platform. To upload files from your local machine to Colab virtual storage, use UPLOAD option from the left sidebar. To download files from Colab's virtual storage to your local machine, right-click on a file and then select ''Download\". You can also mount your google drive: once you click on MOUNT DRIVE in the left sidebar, it will insert a code cell into your notebook that you'll need to run to mount your google drive (it will ask for your authorization). Another way to download files (without mounting a google drive) is to use a `!gdown` or `!wget` commands (more details in the [Shell commands](#scrollTo=JrF12-bqPKPm) section)<br><br>\n","\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1CRjolVrVbEboNPLVVw-c_AtsBBcSou1Z\" width=800 px><br><br>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ZvWtrdMfxQD8"},"source":["## Notebook rules\n","\n","Some basic notebook rules:\n","\n","\n","1.   Click inside a cell with code and press SHIFT+ENTER (or click \"PLAY\" button) to execute it.\n","2.   Re-executing a cell will reset it (any input will be lost).\n","3.   Execute cells TOP TO BOTTOM.\n","5. Notebooks are saved to your Google Drive \n","6. Mount your Google Drive to have a direct access from a notebook to the files stored in the drive (this includes Team Drives).\n","7. If using Colab's virtual storage only, all the uploaded/stored files will get deleted when a runtime is recycled."]},{"cell_type":"markdown","metadata":{"id":"ulev4sV3wc-T"},"source":["## Shell commands"]},{"cell_type":"markdown","metadata":{"id":"fS67zRIavQtS"},"source":["The command `uname` displays the information about the system.\n","\n","* **-a option:** It prints all the system information in the following order: Kernel name, network node hostname, \n","kernel release date, kernel version, machine hardware name, hardware platform, operating system\n","."]},{"cell_type":"code","metadata":{"id":"PT7Umr53u2Qz"},"source":["!uname -a"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i1h8YWW1RzEN"},"source":["!pwd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iseDMLyXT7wG"},"source":["!ls -la drive/MyDrive/GPU_computing/github/GPUcomputing/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NlXMCnBVBkeE"},"source":["!nvcc --version\n","!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MLlLB3gXDKBr"},"source":["!apt-get --purge remove cuda nvidia* libnvidia-*\n","!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n","!apt-get remove cuda-*\n","!apt autoremove\n","!apt-get update"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"38jSDwugDYKB"},"source":["!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n","!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n","!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n","!apt-get update\n","!apt-get install cuda-9.2\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X1EeyR1jBnWR"},"source":["!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7HcKDuAB-CO"},"source":["%load_ext nvcc_plugin"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RlbVvBaXCHBs"},"source":["%%cu\n","//%%writefile example.txt\n","#include <stdio.h>\n","#define N  64\n","\n","inline cudaError_t checkCudaErr(cudaError_t err, const char* msg) {\n","  if (err != cudaSuccess) {\n","    fprintf(stderr, \"CUDA Runtime error at %s: %s\\n\", msg, cudaGetErrorString(err));\n","  }\n","  return err;\n","}\n","\n","__global__ void matrixMulGPU( int * a, int * b, int * c ) {\n","  /*\n","   * Build out this kernel.\n","   */\n","    int row = threadIdx.y + blockIdx.y * blockDim.y;\n","    int col = threadIdx.x + blockIdx.x * blockDim.x;\n","    \n","    int val = 0;\n","    if (row < N && col < N) {\n","      for (int i = 0; i < N; ++i) {\n","         val += a[row * N + i] * b[i * N + col];\n","       }\n","    \n","      c[row * N + col] = val;\n","    }\n","}\n","\n"," /*\n"," * This CPU function already works, and will run to create a solution matrix\n"," * against which to verify your work building out the matrixMulGPU kernel.\n"," */\n","void matrixMulCPU( int * a, int * b, int * c )\n","{\n","  int val = 0;for( int row = 0; row < N; ++row )\n","    for( int col = 0; col < N; ++col )\n","    {\n","      val = 0;\n","      for ( int k = 0; k < N; ++k )\n","        val += a[row * N + k] * b[k * N + col];\n","      c[row * N + col] = val;\n","    }\n","}\n","\n","int main() {\n","  int *a, *b, *c_cpu, *c_gpu; // Allocate a solution matrix for both the CPU and the GPU operationsint \n","  int size = N * N * sizeof (int); // Number of bytes of an N x N matrix// Allocate memory\n","  cudaMallocManaged (&a, size);\n","  cudaMallocManaged (&b, size);\n","  cudaMallocManaged (&c_cpu, size);\n","  cudaMallocManaged (&c_gpu, size);// Initialize memory; create 2D matrices\n","  for( int row = 0; row < N; ++row )\n","    for( int col = 0; col < N; ++col )\n","    {\n","      a[row*N + col] = row;\n","      b[row*N + col] = col+2;\n","      c_cpu[row*N + col] = 0;\n","      c_gpu[row*N + col] = 0;\n","    }\n","   /*\n","   * Assign `threads_per_block` and `number_of_blocks` 2D values\n","   * that can be used in matrixMulGPU above.\n","   */\n","  dim3 threads_per_block(32, 32, 1);\n","  dim3 number_of_blocks(N / threads_per_block.x + 1, N / threads_per_block.y + 1, 1);\n","  matrixMulGPU <<< number_of_blocks, threads_per_block >>> ( a, b, c_gpu );checkCudaErr(cudaDeviceSynchronize(), \"Syncronization\");\n","  checkCudaErr(cudaGetLastError(), \"GPU\");// Call the CPU version to check our work\n","  matrixMulCPU( a, b, c_cpu );// Compare the two answers to make sure they are equal\n","  bool error = false;\n","  for( int row = 0; row < N && !error; ++row )\n","    for( int col = 0; col < N && !error; ++col )\n","      if (c_cpu[row * N + col] != c_gpu[row * N + col])\n","      {\n","        printf(\"FOUND ERROR at c[%d][%d]\\n\", row, col);\n","        error = true;\n","        break;\n","      }\n","  if (!error)\n","    printf(\"Success!\\n\");// Free all our allocated memory\n","  cudaFree(a);\n","  cudaFree(b);\n","  cudaFree( c_cpu );\n","  cudaFree( c_gpu );\n","}\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fWIzTy57JLBW"},"source":["from google.colab import files\n","uploaded = files.upload()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G1K9ok07HlP2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"--LIJInEHnkt"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F9PmBZql0ow4"},"source":["# CUDA zone"]},{"cell_type":"code","metadata":{"id":"vifkJTru0yOg"},"source":[""],"execution_count":null,"outputs":[]}]}